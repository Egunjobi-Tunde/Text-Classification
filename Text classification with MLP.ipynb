{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e148d3-4a4b-4c4f-adde-549e1d00051e",
   "metadata": {},
   "source": [
    "## <div style=\"text-align:center;\">Yelp Revies Sentiment Classification</div>\r",
    " \n",
    "### [SpaCy--> TF-iDF --> MultiLayer Perceptron in Pytorch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c358eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b700ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a horrible experience we had at this reso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So I'm not usually one to fuss, pretty laid ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let me first be clear as to why I gave two sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, it's safe to say that the majority of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This wasn't my first time here, but it's been ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  What a horrible experience we had at this reso...       0\n",
       "1  So I'm not usually one to fuss, pretty laid ba...       0\n",
       "2  Let me first be clear as to why I gave two sta...       0\n",
       "3  Well, it's safe to say that the majority of th...       0\n",
       "4  This wasn't my first time here, but it's been ...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sampled_reviews.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5625e-f8ab-4333-9c67-8e6042dcba74",
   "metadata": {},
   "source": [
    "**Preprocessing with SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80124e83-ba05-465b-81cc-ad978fcee695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocessing(text):\n",
    "    # Tokenize the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize a list to store filtered words\n",
    "    filtered_words = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Convert token text to lowercase\n",
    "        token_text = token.text.lower()\n",
    "\n",
    "        # Check if the token is a stop word or punctuation\n",
    "        if token.is_stop or token_text in string.punctuation:\n",
    "            continue\n",
    "\n",
    "        # Lemmatize the token and add it to the filtered list\n",
    "        lemma = token.lemma_\n",
    "        filtered_words.append(lemma)\n",
    "\n",
    "    # Join the filtered words to form preprocessed text\n",
    "    preprocessed_text = ' '.join(filtered_words)\n",
    "\n",
    "    # Additional text replacements using the provided replacer dictionary\n",
    "    replacer = {\n",
    "        '\\n': '',\n",
    "        \"[\\[].*?[\\]]\": \"\",\n",
    "        '[!\"#%\\'()*+,-./:;<=>?@\\[\\]^_`{|}~1234567890’\"\"′‘\\\\\\]': \"\"\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in replacer.items():\n",
    "        preprocessed_text = re.sub(pattern, replacement, preprocessed_text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    preprocessed_text = ' '.join(preprocessed_text.split())\n",
    "\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85fc0610-c89b-4e9f-80e5-38898958a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the preprocessing on the dataset\n",
    "df['review'] = df['review'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c39e1e-8cea-47f0-a31a-61ba92014cb6",
   "metadata": {},
   "source": [
    "**Vectorizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaba241e-bca5-4c92-8fb8-d276c0ddfd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets.\n",
    "reviews_train, reviews_val, ratings_train, ratings_val = train_test_split(df.review, df.rating, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train = tfidf_vectorizer.fit_transform(reviews_train)\n",
    "\n",
    "# Transform the test data \n",
    "X_test = tfidf_vectorizer.transform(reviews_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c754f9-18bb-4ae1-b378-bec921c625c1",
   "metadata": {},
   "source": [
    "**Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2df59d89-d840-41b1-aeea-e6e3fd178d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Convert TF-IDF matrices to tensors\n",
    "X_train_tensor = torch.Tensor(X_train.toarray())\n",
    "X_test_tensor = torch.Tensor(X_test.toarray())\n",
    "\n",
    "# Convert rating labels to tensors\n",
    "y_train_tensor = torch.Tensor(ratings_train.to_numpy())\n",
    "y_test_tensor = torch.Tensor(ratings_val.to_numpy())\n",
    "# Create DataLoader objects\n",
    "batch_size = 32\n",
    "train_dataset = MyDataset(X_train_tensor,y_train_tensor.view(-1,1))\n",
    "test_dataset = MyDataset(X_test_tensor, y_test_tensor.view(-1,1))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1413bb-79a0-4528-bd1a-4a220f05de91",
   "metadata": {},
   "source": [
    "**Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6ce4fa28-0758-4d53-bd99-f990a1e12b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 64  \n",
    "output_size = 1 \n",
    "\n",
    "model = MLPClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93b201-de79-4ffd-ac14-74033c3424a4",
   "metadata": {},
   "source": [
    "**Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24b70c9b-2b17-4539-907b-8cbdd921c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: [5/50] Loss: 0.1258\n",
      "epochs: [10/50] Loss: 0.0118\n",
      "epochs: [15/50] Loss: 0.0068\n",
      "epochs: [20/50] Loss: 0.0057\n",
      "epochs: [25/50] Loss: 0.0017\n",
      "epochs: [30/50] Loss: 0.0007\n",
      "epochs: [35/50] Loss: 0.0007\n",
      "epochs: [40/50] Loss: 0.0005\n",
      "epochs: [45/50] Loss: 0.0005\n",
      "epochs: [50/50] Loss: 0.0003\n",
      "Training Finished\n",
      "\n",
      "\n",
      "Accuracy on test data: 0.83%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1)%5 ==0:\n",
    "            print(f'epochs: [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}')\n",
    "print('Training Finished')\n",
    "print('\\n')\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs.round()\n",
    "        accuracy = (predicted == labels.view(-1, 1)).float().mean()\n",
    "    print(f\"Accuracy on test data: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb2c4b-310a-44d0-847d-57a3556a9e54",
   "metadata": {},
   "source": [
    "**With a better computation power, more data can be used and the model can be re-trained. Random sample of 4000 rows of Yelp Sentiment dataset was used.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6763808a-e1ef-4ee8-a96d-419762af0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'sentiment_mlp_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
